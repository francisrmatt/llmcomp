ALPHABET = 128
cw = 256
bs = 50
lr = 1e-5
vocab_size = 256
embedding_dim = 128
num_layers = 16
num_heads = 8
emb_init_scale = 0.02
widening_factor = 4
training: ?
no scaling