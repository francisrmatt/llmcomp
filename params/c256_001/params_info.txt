cw = 256
bs = 1
lr = 1e-5
vocab_size = 256
embedding_dim = 128
num_layers = 16
num_heads = 8
emb_init_scale = 0.02
widening_factor = 4
training: 60e3